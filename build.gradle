/*
 * Copyright (c) 2007-2013 Concurrent, Inc. All Rights Reserved.
 *
 * Project and contact information: http://www.concurrentinc.com/
 */

apply plugin: 'java'
apply plugin: 'idea'

evaluationDependsOn( 'logparser' )
evaluationDependsOn( 'loganalysis' )
evaluationDependsOn( 'wordcount' )
evaluationDependsOn( 'hadoop' )

repositories {
  mavenLocal()
  mavenCentral()
  maven {
      url 'http://conjars.org/repo/'
  }
  maven {
      url 'https://repository.apache.org/content/repositories/releases/'
  }
  maven {
      url 'http://maven-qubole.s3-website-us-east-1.amazonaws.com/maven/release'
  }
  maven {
      url 'http://maven-qubole.s3-website-us-east-1.amazonaws.com/maven/snapshot'
  }
}

if( project.properties[ 'teamcity' ] ) // make them system properties
  System.properties.putAll( project.properties[ 'teamcity' ] )

if( System.properties[ 'aws.properties' ] )
{
  file( System.properties[ 'aws.properties' ] ).withReader { reader ->
    def awsProperties = new Properties()
    awsProperties.load( reader )
    System.properties.putAll( awsProperties )
  }
}

def hadoopHome = System.properties[ 'hadoop.home' ]

ext.cascadingVersionMajor = '2.6.3'

ext.commandLines = [
        logparser: "jar logparser.jar data/apache.200.txt output",
        loganalysis: "jar loganalysis.jar data/apache.200.txt output",
        wordcount: "jar wordcount.jar data/url+page.200.txt output local",
        hadoop: "jar hadoop.jar data/apache.200.txt output"
]

ext.numParts = [
        logparser: 1,
        loganalysis: 3,
        wordcount: 5,
        hadoop: 1
]

subprojects {

  configurations {
    sshAntTask
    s3AntTask
  }

  dependencies {
    sshAntTask 'org.apache.ant:ant-jsch:1.7.1', 'jsch:jsch:0.1.29'
    s3AntTask 'thirdparty:awstasks:0.3'
  }

  def verifyPath = "${buildDir}/verify/"
  def execPath = "${verifyPath}/${project.name}"

  task unpackDist( dependsOn: 'dist' ) {
    ext.archivePath = tasks[ 'dist' ].archivePath
  }

  unpackDist << {
    ant.untar( src: archivePath, dest: verifyPath, compression: "gzip" )
  }

  task execSample( dependsOn: unpackDist ) {
    description = 'execute all samples using $hadoop.home property, disable with $execsample.skip=true'
    enabled = System.properties[ 'execsample.skip' ] != 'true'
  }

  execSample << {

    assert hadoopHome
    ant.exec( dir: execPath, executable: "${hadoopHome}/bin/hadoop", output: "${verifyPath}/console.txt" ) {
      arg( line: commandLines[ project.name ] )
    }
  }

  execSample << {
    assert fileTree( execPath ).include( '**/part-00000' ).getFiles().size() == numParts[ project.name ]
    println "${project.name} PASSED exec dist tests"
  }

  task s3Upload( dependsOn: execSample ) {

    ext.awsAccessId = System.properties[ 'publish.aws.accessId' ]
    ext.awsSecretKey = System.properties[ 'publish.aws.secretKey' ]
    ext.s3Bucket = System.properties[ 'publish.bucket' ]

    ext.remotePath = "samples/${cascadingVersionMajor}/${project.name}/"
  }

  s3Upload << {

    ant.taskdef( name: 's3Upload', classname: 'dak.ant.taskdefs.S3Upload',
            classpath: configurations.s3AntTask.asPath )

    def currentPath = new File( buildDir, 'latest.txt' )

    currentPath.write( "http://${s3Bucket}/${remotePath}${dist.archivePath.name}" )

    ant.s3Upload( verbose: 'true', accessId: awsAccessId, secretKey: awsSecretKey,
            bucket: s3Bucket, prefix: remotePath, publicRead: 'true' ) {
      fileset( file: dist.archivePath )
      fileset( file: currentPath )
    }

    currentPath.delete()
  }

  task sitePublish( dependsOn: s3Upload ) << {

    def publishBucket = System.properties[ 'publish.bucket' ]
    def publishDownloadPath = System.properties[ 'publish.download.path' ]
    def publishPort = !System.properties[ 'publish.port' ] ? '22' : System.properties[ 'publish.port' ]
    def publishKeyFile = System.properties[ 'publish.keyfile' ]

    def currentPath = new File( buildDir, 'latest.txt' )

    currentPath.write( "http://${publishBucket}/samples/${cascadingVersionMajor}/${project.name}/${dist.archivePath.name}" )

    ant.taskdef( name: 'scp', classname: 'org.apache.tools.ant.taskdefs.optional.ssh.Scp',
            classpath: configurations.sshAntTask.asPath )

    def remoteToFile = "${publishDownloadPath}/samples/${cascadingVersionMajor}/${project.name}/latest.txt"

    ant.scp( file: currentPath, remoteToFile: remoteToFile,
            keyfile: publishKeyFile, passphrase: '', port: publishPort, trust: 'true' )

    currentPath.delete()
  }
}

task updateBuildFile() << {

  subprojects.each { sub ->

    if( sub.name != 'hadoop' )
    {
      copy {
        from 'sample.build.gradle'
        into sub.projectDir
        rename { file -> 'build.gradle'}
      }
    }
  }
}
